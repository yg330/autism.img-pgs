---
title: "Across cohort Analysis"
author: "Yuanjun Gu"
date: "2023-05-31"
output: html_document
---
### t and F test between cohort
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # General code writing
library(here) # For reproducibility, remember open new project at the pgs_img folder
library(jtools) # For automation of summarizing lm models
library(huxtable, include.only = 'huxreg') # dependency of export_summ() in jtools package
library(Hmisc, include.only = 'rcorr') # For correlation matrix generation
library(corrplot) # For correlation matrix plot
library(data.table, include.only = "fread") # For fast data read-in
library(ggseg) # For brain plot
library(ggsegGlasser) # For Glasser segmentation specifically, note: ggsegGlasser is not avaliable for this version of R[4.3.0], but I've downloaded through ggseg r-universe frollowing their github recommendation.
library(car, include.only = 'vif') # for checking colinearity
library(patchwork) # For adding plots together
library(ggpubr) # For generating publication ready graphs
library(openxlsx)
```

```{r UKB, echo=FALSE}

UKBasd <- read.csv(here("PGS/UKB/Autism_grove_ipsychonly2020_PRSCS.txt"), header = T, sep = " ") # unstratified
fUKBasd <- read.csv(here("PGS/UKB/Autism_grove_ipsychonly2020_females_PRSCS.txt"), header = T, sep = " ") # female
mUKBasd <- read.csv(here("PGS/UKB/Autism_grove_ipsychonly2020_males_PRSCS.txt"), header = T, sep = " ") # male

struc_pheno <- read.csv(here("QCd_pheno_covar/UKB/Structural_WB.txt"), header = T, sep = " ") # structural phenotypes
scale_pheno <- read.csv(here("QCd_pheno_covar/UKB/WMpheno_scaled.txt"), header = T, sep = " ") # diffusion phenotypes

struc_covar <- read.csv(here("QCd_pheno_covar/UKB/WMcovardiscrete_structural.txt"), header =T, sep = " ")
scale_covar <- read.csv(here("QCd_pheno_covar/UKB/WMqcovar.txt"), header =T, sep = " ")
batch_covar <- read.csv(here("QCd_pheno_covar/UKB/UKB_whitmatterandsomecovars.txt"), header =T, sep = " ") # not standardized data, only needed f.22000.0.0 for sequencing batch number

summary(batch_covar$Age) # summary of age before being scaled

batch_covar <- batch_covar[, c("f.eid", "f.22000.0.0")]
# Only struc_pheno has higher (37509) obj than the rest of the dataset (31797)

UKB.Data <- read.csv(here("QCd_pheno_covar/UKB/eTIV.csv"), header = T, sep = ",") # Read-in UKB data given by Richard
UKB.Data$IID <- as.integer(gsub("UKB", "", UKB.Data$participant)) # participant = UKB+IID
UKB.Data$FID <- as.integer(gsub("UKB", "", UKB.Data$participant))
UKB.Data <- UKB.Data[, c("FID", "IID", "dx")] # Grabbing data needed only

covar <- full_join(scale_covar, struc_covar, by = c("FID", "IID"))
batch_covar <- rename(batch_covar, "IID" = "f.eid") # confirmed that f.eid is the same as IID as well as FID
batch_covar <- rename(batch_covar, "batchID" = "f.22000.0.0") #rename to understandable label
covar <- full_join(covar, batch_covar, by = "IID")
covar <- rename(covar, "T1T2" = "Covar") # update to correct covar name
covar$T1T2[covar$T1T2 == "T1"] <- 0      # correct label T1   (which actually is T1T1) to correct binary value
covar$T1T2[covar$T1T2 == "T1T1"] <- 1    # correct label T1T1 (which actually is T1T2) to correct binary value
remove(struc_covar, scale_covar, batch_covar) # remove unused object

fUKBasd <- rename(fUKBasd, "ftotalsum" = "totalsum", "fPGS_scaled" = "PGS_scaled") # rename so when creating master data set it is not merged
mUKBasd <- rename(mUKBasd, "mtotalsum" = "totalsum", "mPGS_scaled" = "PGS_scaled") # rename so when creating master data set it is not merged
pgs.img <- list(covar, UKBasd, fUKBasd, mUKBasd, scale_pheno, struc_pheno, UKB.Data)
pgs.img <- pgs.img %>% reduce(full_join, by= c("IID", "FID")) # merge data sets
pgs.img <- pgs.img[!is.na(pgs.img$Age),] # Drop NAs by as they will only include structure phenotype not any other info

pgs.img$cohort <-ifelse(pgs.img$Sex==0, "female", NA) # create new column cohort for easy grouping in plot with consideration of NA
pgs.img$cohort <-ifelse(pgs.img$Sex==1, "male", pgs.img$cohort) # create new column cohort for easy grouping in plot

remove(covar, fUKBasd, mUKBasd, scale_pheno, struc_pheno, UKBasd, UKB.Data) # remove unused object

# Scale, as PCA, eular, fd, scan.site, batchID, Sex, T1T2 not scaled
pgs.img$T1T2 <- as.numeric(pgs.img$T1T2)
pgs.img[c(7:53)] <- scale(pgs.img[c(7:53)])
```

```{r ABCD, echo=FALSE}
# Note: Age = months, age is 0/1 coded, age_squared = age*age, age_sex was done by age*sex column directly, how age_sexsquared is generated unknown
# No T1T2 status, No batch ID

Covar <- read.csv(here("QCd_pheno_covar/ABCD/ABCD_allcovariates.txt"), header = T, sep = "\t") # row 10584 - 10589 is NA
Covar <- drop_na(Covar) # Assume it is normal and delete these rows
Covar$site_id_l <- gsub("site","", Covar$site_id_l) # delete 'site' to make site number a numeric column
Covar$site_id_l <- as.numeric(Covar$site_id_l) # change value class as numeric

Pheno <- read.csv(here("QCd_pheno_covar/ABCD/ABCD_corticalpheno.txt"), header = T, sep = " ")  # Miss 20 people in comparison to 10583 in the Covar
ABCD <- full_join(Covar, Pheno, by = c("FID", "IID")) # merge data that are shared between two datasets
ABCD <- drop_na(ABCD) # Eliminated all NAs, for more info on why use colSums(is.na(ABCD))

gPCA <- fread(here("QCd_pheno_covar/ABCD/ABCD_PCsforGWAS_European.txt"))
gPCA <- rename(gPCA, IID = Sample_name) # Change name for merging
gPCA <- gPCA[,c(1:11)] # Only leave lm model relevant amount of PCAs
Covar <- full_join(Covar, gPCA, by = "IID") # merge data that are shared between two datasets

ABCD <- full_join(Covar, Pheno, by = c("FID", "IID")) # merge data that are shared between two datasets
ABCD <- ABCD[, c(1:5, 8:22, 28:29, 32:33)] # leave only relevant phenotypes, ABCD don't have T1T2 status

ABCD$cohort <-ifelse(ABCD$gender==1, "female", NA) # create new column cohort for easy grouping in plot with consideration of NA
ABCD$cohort <-ifelse(ABCD$gender==0, "male", ABCD$cohort) 

ABCD <- rename(ABCD, Sex = gender) # Rename For better code translation from UKB to ABCD
ABCD <- rename(ABCD, Age = interview_age)

# Read-in scores, rename and reformat data set for merging with ABCD
PGS <- fread(here("PGS/ABCD/autism_unstratified_finalscore.profile"))
PGS$PGS <- scale(PGS$SCORE) # Scaled numbers
PGS <- PGS[,c(2, 7)]

fPGS <- fread(here("PGS/ABCD/autism_females_finalscore.profile"))
fPGS$fPGS <- scale(fPGS$SCORE) # Scaled numbers
fPGS <- fPGS[,c(2, 7)]

mPGS <- fread(here("PGS/ABCD/autism_males_finalscore.profile"))
mPGS$mPGS <- scale(mPGS$SCORE) # Scaled numbers
mPGS <- mPGS[,c(2, 7)]

# Merge PGS, fPGS and mPGS score to ABCD
ABCD <- list(ABCD, PGS, fPGS, mPGS) %>% reduce(left_join, by= c("IID"))
ABCD <- drop_na(ABCD)

summary(ABCD$Age/12) # Summary of Age By Month thus we can get summary for age in years before being scaled

# Scale All variables
ABCD[c(3:24)] <- scale(ABCD[c(3:24)])

remove(Covar, Pheno, gPCA, fPGS, mPGS, PGS) # Remove dataset
```

```{r merge datasets}
ABCD <- ABCD[20:23]
ABCD$cohort <- "ABCD"
ABCD <- rename(ABCD, "MC" = "meanCurv", "ICVF" = "NODDI_ICVF")


pgs.img <- pgs.img[c(60,66,69,70)]
pgs.img$cohort <- "UKB"
pgs.img <- rename(pgs.img, "SA" = "Struct_SA", "CT" = "Struct_CT", "MC" = "Struct_meanCurv", "ICVF" = "meanNODDI_ICVF")

ALL <- full_join(ABCD, pgs.img)
```

```{r t and F test to test cohort mean and variance difference in SD}
# F-test
var.test(SA ~ cohort, data = ALL)
var.test(CT ~ cohort, data = ALL)
var.test(MC ~ cohort, data = ALL)
var.test(ICVF ~ cohort, data = ALL)

# t-test
# In R, t-test default assumes unequal variance so no need for additional arguments
t.test(SA ~ cohort, data = ALL)
t.test(CT ~ cohort, data = ALL)
t.test(MC ~ cohort, data = ALL)
t.test(ICVF ~ cohort, data = ALL)

denSA <- ggdensity(ALL, x = "SA",add = "mean", color = "cohort", fill = "cohort", palette = c("#FF9999", "#00AFBB")) + xlim(-5,5) + ylim(0.0, 0.6) + 
  labs(fill = "cohort", color = "cohort", x = "Surface Area in SD")
denSA

denCT <- ggdensity(ALL, x = "CT",add = "mean", color = "cohort", fill = "cohort", palette = c("#FF9999", "#00AFBB")) + xlim(-5,5) + ylim(0.0, 0.6) + 
  labs(fill = "cohort", color = "cohort", x = "Cortical Thickness in SD")
denCT

denMC <- ggdensity(ALL, x = "MC",add = "mean", color = "cohort", fill = "cohort", palette = c("#FF9999", "#00AFBB")) + xlim(-5,5) + ylim(0.0, 0.6) + 
  labs(fill = "cohort", color = "cohort", x = "Mean Curvature in SD")
denMC

denICVF <- ggdensity(ALL, x = "ICVF",add = "mean", color = "cohort", fill = "cohort", palette = c("#FF9999", "#00AFBB")) + xlim(-5,5) + ylim(0.0, 0.6) + 
  labs(fill = "cohort", color = "cohort", x = "Intracellular Volume Fraction in SD")
denICVF
```

### Correlation Matrix between cohort
```{r correlation between regional ABCD and UKB results}
# Read in file list
UKB_path.list = list.files(path = here("Result_Table/"), pattern = "UKB_",full.names = TRUE) # Only find saved regional associations)
UKB_path.list = UKB_path.list[grepl("PGS", UKB_path.list, fixed = TRUE)]
UKB_path.list = UKB_path.list[!grepl("sig", UKB_path.list, fixed = TRUE)]
UKB_path.list = UKB_path.list[!grepl("glb", UKB_path.list, fixed = TRUE)]
UKB_path.list = UKB_path.list[!grepl("tract", UKB_path.list, fixed = TRUE)]

ABCD_path.list = list.files(path = here("Result_Table/"), pattern = "ABCD_", full.names = TRUE)
ABCD_path.list = ABCD_path.list[grepl("PGS", ABCD_path.list, fixed = TRUE)]
ABCD_path.list = ABCD_path.list[!grepl("sig", ABCD_path.list, fixed = TRUE)]
ABCD_path.list = ABCD_path.list[!grepl("glb", ABCD_path.list, fixed = TRUE)]

# Loop and merge to get UKB master sheet for each regression model
for (i in seq(UKB_path.list)) {
  sheet_1 = read.xlsx(UKB_path.list[i], sheet = 1)
  sheet_1$p.adj = p.adjust(sheet_1$p, method = "fdr", n = 180) # adjust p value with multiple correction
  sheet_2 = read.xlsx(UKB_path.list[i], sheet = 2)
  sheet_2$p.adj = p.adjust(sheet_2$p, method = "fdr", n = 180)
  sheet_3 = read.xlsx(UKB_path.list[i], sheet = 3)
  sheet_3$p.adj = p.adjust(sheet_3$p, method = "fdr", n = 180)
  sheet_4 = read.xlsx(UKB_path.list[i], sheet = 4)
  sheet_4$p.adj = p.adjust(sheet_4$p, method = "fdr", n = 180)
  sheet_5 = read.xlsx(UKB_path.list[i], sheet = 5)
  sheet_5$p.adj = p.adjust(sheet_5$p, method = "fdr", n = 180)
  
  master_sheet = list(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5) %>% reduce(full_join) # Merge into one sheet
  
  # Change region name to readable formate for brain visualisation package
  master_sheet$region <- gsub("_ROI","",as.character(master_sheet$region)) # Remove _ROI
  master_sheet$region <- gsub("X","",as.character(master_sheet$region)) # Remove X to fit format
  master_sheet$region <- gsub("ROI","L",as.character(master_sheet$region)) # Replace ROI with L to fit format
  master_sheet$region <- gsub("\\.","-",as.character(master_sheet$region)) # Replace . as - to fit format
  
  master_sheet$sig = ifelse(master_sheet$p.adj<0.05, "sig", "not sig") # Add sig label
  master_sheet$cohort = "UKB"
  
  dataframe_name = gsub(here("Result_Table//"), "", UKB_path.list[i])
  dataframe_name = gsub(".xlsx", "", dataframe_name)
  dataframe_name = gsub("UKB/", "UKB_", dataframe_name)
  assign(dataframe_name, master_sheet)
}

for (i in 6:7) { # these are numbers corresponding to UKB_path.list[i] with PGS:Sex models
  sheet_1 = read.xlsx(UKB_path.list[i], sheet = 6)
  sheet_1$p.adj = p.adjust(sheet_1$p, method = "fdr", n = 180) # adjust p value with multiple correction
  sheet_2 = read.xlsx(UKB_path.list[i], sheet = 7)
  sheet_2$p.adj = p.adjust(sheet_2$p, method = "fdr", n = 180)
  sheet_3 = read.xlsx(UKB_path.list[i], sheet = 8)
  sheet_3$p.adj = p.adjust(sheet_3$p, method = "fdr", n = 180)
  sheet_4 = read.xlsx(UKB_path.list[i], sheet = 9)
  sheet_4$p.adj = p.adjust(sheet_4$p, method = "fdr", n = 180)
  sheet_5 = read.xlsx(UKB_path.list[i], sheet = 10)
  sheet_5$p.adj = p.adjust(sheet_5$p, method = "fdr", n = 180)
  
  master_sheet = list(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5) %>% reduce(full_join) # Merge into one sheet
  
  # Change region name to readable formate for brain visualisation package
  master_sheet$region <- gsub("_ROI","",as.character(master_sheet$region)) # Remove _ROI
  master_sheet$region <- gsub("X","",as.character(master_sheet$region)) # Remove X to fit format
  master_sheet$region <- gsub("ROI","L",as.character(master_sheet$region)) # Replace ROI with L to fit format
  master_sheet$region <- gsub("\\.","-",as.character(master_sheet$region)) # Replace . as - to fit format
  
  master_sheet$sig = ifelse(master_sheet$p.adj<0.05, "sig", "not sig") # Add sig label
  master_sheet$cohort = "UKB"
  
  dataframe_name = gsub(here("Result_Table//"), "", UKB_path.list[i])
  dataframe_name = gsub(".xlsx", "", dataframe_name)
  dataframe_name = paste0(dataframe_name, "PGS:Sex")
  dataframe_name = gsub("UKB/", "UKB_", dataframe_name)
  assign(dataframe_name, master_sheet)
}




# Loop and merge to get ABCD master sheet for each regression model
for (i in seq(ABCD_path.list)) {
  sheet_1 = read.xlsx(ABCD_path.list[i], sheet = 1)
  sheet_1$p.adj = p.adjust(sheet_1$p, method = "fdr", n = 180) # adjust p value with multiple correction
  sheet_2 = read.xlsx(ABCD_path.list[i], sheet = 2)
  sheet_2$p.adj = p.adjust(sheet_2$p, method = "fdr", n = 180)
  sheet_3 = read.xlsx(ABCD_path.list[i], sheet = 3)
  sheet_3$p.adj = p.adjust(sheet_3$p, method = "fdr", n = 180)
  sheet_4 = read.xlsx(ABCD_path.list[i], sheet = 4)
  sheet_4$p.adj = p.adjust(sheet_4$p, method = "fdr", n = 180)
  sheet_5 = read.xlsx(ABCD_path.list[i], sheet = 5)
  sheet_5$p.adj = p.adjust(sheet_5$p, method = "fdr", n = 180)
  
  master_sheet = list(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5) %>% reduce(full_join) # Merge into one sheet
  
  # Change region name to readable formate for brain visualisation package
  master_sheet$region <- gsub("_ROI","",as.character(master_sheet$region)) # Remove _ROI
  master_sheet$region <- gsub("X","",as.character(master_sheet$region)) # Remove X to fit format
  master_sheet$region <- gsub("ROI","L",as.character(master_sheet$region)) # Replace ROI with L to fit format
  master_sheet$region <- gsub("\\.","-",as.character(master_sheet$region)) # Replace . as - to fit format
  
  master_sheet$sig = ifelse(master_sheet$p.adj<0.05, "sig", "not sig") # Add sig label
  master_sheet$cohort = "ABCD"
  
  dataframe_name = gsub(here("Result_Table//"), "", ABCD_path.list[i])
  dataframe_name = gsub(".xlsx", "", dataframe_name)
  assign(dataframe_name, master_sheet)
}

for (i in 6:7) { # these are numbers corresponding to ABCD_path.list[i] with PGS:Sex models
  sheet_1 = read.xlsx(ABCD_path.list[i], sheet = 6)
  sheet_1$p.adj = p.adjust(sheet_1$p, method = "fdr", n = 180) # adjust p value with multiple correction
  sheet_2 = read.xlsx(ABCD_path.list[i], sheet = 7)
  sheet_2$p.adj = p.adjust(sheet_2$p, method = "fdr", n = 180)
  sheet_3 = read.xlsx(ABCD_path.list[i], sheet = 8)
  sheet_3$p.adj = p.adjust(sheet_3$p, method = "fdr", n = 180)
  sheet_4 = read.xlsx(ABCD_path.list[i], sheet = 9)
  sheet_4$p.adj = p.adjust(sheet_4$p, method = "fdr", n = 180)
  sheet_5 = read.xlsx(ABCD_path.list[i], sheet = 10)
  sheet_5$p.adj = p.adjust(sheet_5$p, method = "fdr", n = 180)
  
  master_sheet = list(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5) %>% reduce(full_join) # Merge into one sheet
  
  # Change region name to readable formate for brain visualisation package
  master_sheet$region <- gsub("_ROI","",as.character(master_sheet$region)) # Remove _ROI
  master_sheet$region <- gsub("X","",as.character(master_sheet$region)) # Remove X to fit format
  master_sheet$region <- gsub("ROI","L",as.character(master_sheet$region)) # Replace ROI with L to fit format
  master_sheet$region <- gsub("\\.","-",as.character(master_sheet$region)) # Replace . as - to fit format
  
  master_sheet$sig = ifelse(master_sheet$p.adj<0.05, "sig", "not sig") # Add sig label
  master_sheet$cohort = "ABCD"
  
  dataframe_name = gsub(here("Result_Table//"), "", ABCD_path.list[i])
  dataframe_name = gsub(".xlsx", "", dataframe_name)
  dataframe_name = paste0(dataframe_name, "PGS:Sex")
  assign(dataframe_name, master_sheet)
}

remove(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5, master_sheet, dataframe_name, i)
```

```{r correlation coefficient between cohort}
SA.cor <- cor.test(UKB_reg.img_PGS[which(UKB_reg.img_PGS$IMG == "SA"),]$beta, ABCD_reg.img_PGS[which(ABCD_reg.img_PGS$IMG == "SA"),]$beta, method = "pearson")
SA.cor

CT.cor <- cor.test(UKB_reg.img_PGS[which(UKB_reg.img_PGS$IMG == "CT"),]$beta, ABCD_reg.img_PGS[which(ABCD_reg.img_PGS$IMG == "CT"),]$beta, method = "pearson")
CT.cor

MC.cor <- cor.test(UKB_reg.img_PGS[which(UKB_reg.img_PGS$IMG == "MC"),]$beta, ABCD_reg.img_PGS[which(ABCD_reg.img_PGS$IMG == "MC"),]$beta, method = "pearson")
MC.cor

ICVF.cor <- cor.test(UKB_reg.img_PGS[which(UKB_reg.img_PGS$IMG == "ICVF"),]$beta, ABCD_reg.img_PGS[which(ABCD_reg.img_PGS$IMG == "ICVF"),]$beta, method = "pearson")
ICVF.cor

ISOVF.cor <- cor.test(UKB_reg.img_PGS[which(UKB_reg.img_PGS$IMG == "ISOVF"),]$beta, ABCD_reg.img_PGS[which(ABCD_reg.img_PGS$IMG == "ISOVF"),]$beta, method = "pearson")
ISOVF.cor

```

### Global and Regional association visualisation between cohorts
```{r Global IncR2 between cohorts}
# Read in data and label cohort
UKB.incR2 = read.csv(here("Result_Table/UKB_glb.img_incR2.txt"))
UKB.incR2$Cohort = "UKB"
ABCD.incR2 = read.csv(here("Result_Table/ABCD_glb.img_incR2.txt"))
ABCD.incR2$Cohort = "ABCD"

# Subset data
UKB.incR2.sex_diff = subset(UKB.incR2, Population != "Unstratified")
UKB.incR2 = subset(UKB.incR2, Population == "Unstratified")

ABCD.incR2.sex_diff = subset(ABCD.incR2, Population != "Unstratified")
ABCD.incR2 = subset(ABCD.incR2, Population == "Unstratified")

inc.R2 = full_join(UKB.incR2, ABCD.incR2)
inc.R2.sex_diff = full_join(UKB.incR2.sex_diff, ABCD.incR2.sex_diff)

# Merge and create barplot
pub.inc.R2.fig <- ggbarplot(inc.R2, x = "IMG", y = "adj.R2", fill = "association", facet.by = "Cohort") + 
  scale_fill_manual(values=c("skyblue", "tomato")) + 
  scale_color_manual(values=c("skyblue", "tomato")) + 
  labs(y = "Variance explained in %", x = "MRI Phenotype") + scale_y_continuous(labels = scales::comma) + 
  geom_text(aes(label = Sig.level), col = "black", vjust = -0.1) + geom_hline(yintercept = 0)

pub.inc.R2.fig
```

```{r Global sex inter and sex specific IncR2 between cohorts, fig.height=5}
# Read in data and label cohort
UKB.incR2.sex_int = read.csv(here("Result_Table/UKB_glb.img_incR2.sex.txt"))
UKB.incR2.sex_int$Cohort = "UKB"

ABCD.incR2.sex_int = read.csv(here("Result_Table/ABCD_glb.img_incR2.sex.txt"))
ABCD.incR2.sex_int$Cohort = "ABCD"

inc.R2.sex_int = full_join(UKB.incR2.sex_int, ABCD.incR2.sex_int)

# Manipulations for merging sex diff and sex int together
inc.R2.sex_diff = inc.R2.sex_diff[,c(1:6,9:10,12)] # Remove PGS:Sex related empty columns
inc.R2.sex_int = inc.R2.sex_int[,c(1:4,7:11)] # Remove none-PGS:Sex columns and rename them
inc.R2.sex_int = rename(inc.R2.sex_int, "association" = "PGS.Sex.association", "p.val" = "PGS.Sex.p.val", "Sig.level" = "Sig.level.sex")

inc.R2.all_sex = full_join(inc.R2.sex_diff, inc.R2.sex_int)

# Create barplot
pub.inc.R2.fig.sex <- ggbarplot(inc.R2.all_sex, x = "IMG", y = "adj.R2", fill = "association") + 
  scale_fill_manual(values=c("skyblue", "tomato")) + 
  scale_color_manual(values=c("skyblue", "tomato")) + 
  facet_grid(rows = vars(PGS.Label), cols = vars(Cohort)) +
  labs(y = "Variance explained in %", x = "MRI Phenotype") + scale_y_continuous(labels = scales::comma) + 
  geom_hline(yintercept = 0) + 
  geom_text(aes(label = Sig.level), col = "black", vjust = 0.4)

pub.inc.R2.fig.sex

```


```{r Read in and manipulate regional Associations between cohorts for reg associations only}
reg.img_PGS = full_join(ABCD_reg.img_PGS, UKB_reg.img_PGS)
```

```{r Visualisation of regional associations, fig.height=8, fig.width=12}
# By cohort and phenotype
reg.sig = full_join(UKB_reg.img_PGS, ABCD_reg.img_PGS)

reg.sig.vis = reg.sig %>% group_by(cohort, IMG) %>% ggseg(mapping = aes(fill = beta, col = sig), atlas = "glasser", hemisphere = "right", position = "stacked") + 
  scale_fill_gradient2(low = "#2E3B79", mid="white",high="#F7B738") + 
  scale_colour_manual(values=c("lightgrey", "red")) +
  labs(fill = "PGS beta") + 
  theme(legend.position = "right", axis.title.x = element_blank(), 
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        strip.text.x = element_text(size = 14)) + guides(col = "none") + facet_grid(rows = vars(IMG), cols = vars(cohort))

plot(reg.sig.vis)
ggsave(plot = reg.sig.vis, filename = here("Result_Figure/Pub.reg.sig.vis.15032024.pdf"), width = 15, height = 12)

reg.sig.adj = full_join(`UKB_reg.img_PGS+Glb.img`, `ABCD_reg.img_PGS+Glb.img`)

reg.sig.adj.vis = reg.sig.adj %>% group_by(cohort, IMG) %>% ggseg(mapping = aes(fill = beta, col = sig), atlas = "glasser", hemisphere = "right", position = "stacked") + 
  scale_fill_gradient2(low = "#2E3B79", mid="white",high="#F7B738") + 
  scale_colour_manual(values=c("lightgrey", "red")) +
  labs(fill = "PGS beta") + 
  theme(legend.position = "right", axis.title.x = element_blank(), 
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        strip.text.x = element_text(size = 14)) + guides(col = "none") + facet_grid(rows = vars(IMG), cols = vars(cohort))

plot(reg.sig.adj.vis)
ggsave(plot = reg.sig.adj.vis, filename = here("Result_Figure/Pub.reg.sig.adj.vis.15032024.pdf"), width = 15, height = 12)

# group_by was nessersary otherwise would also plot NA
UKB_reg.sig = subset(UKB_reg.img_PGS, IMG == "ICVF" | IMG == "SA")
ABCD_reg.sig = subset(ABCD_reg.img_PGS, IMG == "ICVF" | IMG == "MC" | IMG == "ISOVF")

UKB_pub.reg.vis = UKB_reg.sig %>% group_by(IMG) %>% ggseg(mapping = aes(fill = beta, col = sig), atlas = "glasser", hemisphere = "right", position = "stacked") + 
  scale_fill_gradient2(low = "#2E3B79", mid="white",high="#F7B738") + 
  scale_colour_manual(values=c("lightgrey", "red")) +
  labs(fill = "PGS beta") + 
  theme(legend.position = "right", axis.title.x = element_blank(), 
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        strip.text.x = element_text(size = 14)) + guides(col = "none") + facet_grid(rows = vars(IMG))

UKB_pub.reg.vis


ABCD_pub.reg.vis = ABCD_reg.sig %>% group_by(IMG) %>% ggseg(mapping = aes(fill = beta, col = sig), atlas = "glasser", hemisphere = "right", position = "stacked") + 
  scale_fill_gradient2(low = "#2E3B79", mid="white",high="#F7B738") + 
  scale_colour_manual(values=c("lightgrey", "red")) +
  labs(fill = "PGS beta") + 
  theme(legend.position = "right", axis.title.x = element_blank(), 
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        strip.text.x = element_text(size = 14)) + guides(col = "none") + facet_grid(rows = vars(IMG))

ABCD_pub.reg.vis

```


### Hubness between cohorts
```{r hubness}
reg.path.list = list.files(path = here("Result_Table/"), pattern = "UKB_reg.img_PGS.xlsx" , full.names = TRUE)
reg.path.list = append(reg.path.list, list.files(path = here("Result_Table/"), pattern = "ABCD_reg.img_PGS.xlsx" , full.names = TRUE))

# Loop and merge to get master sheet for each regression model
for (i in seq(reg.path.list)) {
  sheet_1 = read.xlsx(reg.path.list[i], sheet = 1)
  sheet_1$p.adj = p.adjust(sheet_1$p, method = "fdr", n = 180) # adjust p value with multiple correction
  sheet_2 = read.xlsx(reg.path.list[i], sheet = 2)
  sheet_2$p.adj = p.adjust(sheet_2$p, method = "fdr", n = 180)
  sheet_3 = read.xlsx(reg.path.list[i], sheet = 3)
  sheet_3$p.adj = p.adjust(sheet_3$p, method = "fdr", n = 180)
  sheet_4 = read.xlsx(reg.path.list[i], sheet = 4)
  sheet_4$p.adj = p.adjust(sheet_4$p, method = "fdr", n = 180)
  sheet_5 = read.xlsx(reg.path.list[i], sheet = 5)
  sheet_5$p.adj = p.adjust(sheet_5$p, method = "fdr", n = 180)
  
  master_sheet = list(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5) %>% reduce(full_join) # Merge into one sheet
  
  # Change region name to readable formate for brain visualisation package
  master_sheet$region <- gsub("_ROI","",as.character(master_sheet$region)) # Remove _ROI
  master_sheet$region <- gsub("X","",as.character(master_sheet$region)) # Remove X to fit format
  master_sheet$region <- gsub("ROI","L",as.character(master_sheet$region)) # Replace ROI with L to fit format
  master_sheet$region <- gsub("\\.","-",as.character(master_sheet$region)) # Replace . as - to fit format
  
  master_sheet$sig = ifelse(master_sheet$p.adj<0.05, "sig", "not sig") # Add sig label
  
  dataframe_name = gsub(here("Result_Table//"), "", reg.path.list[i])
  dataframe_name = gsub(".xlsx", "", dataframe_name)
  assign(dataframe_name, master_sheet)
}
remove(sheet_1, sheet_2, sheet_3, sheet_4, sheet_5, master_sheet, dataframe_name, i, reg.path.list)

# Hubness Visualisation
ABCD_reg.img_PGS$cohort = "ABCD"
UKB_reg.img_PGS$cohort = "UKB"
reg.img_PGS = full_join(ABCD_reg.img_PGS, UKB_reg.img_PGS)

hubness = fread(here("Result_Table/genetic_hubness_by_Varun.txt"), drop = "V1")
hubness = rename("IMG" = "phenotype", "region_n" = "region", "region" = "region_name", hubness)

hubness.vis = merge(reg.img_PGS, hubness, by = c("IMG", "region"))
hubness.vis$show_region = ifelse(hubness.vis$sig == "sig", hubness.vis$region, NA)

ggscatter(hubness.vis, x = "beta", y = "hubness", add = "reg.line", conf.int = TRUE, cor.coef = TRUE, cor.method = "pearson", 
          xlab = "PGS beta", ylab = "genetic hubness", size = 1) + geom_point(aes(colour=sig)) + ylim(0,1.5) + 
  facet_grid(rows = vars(IMG), cols = vars(cohort))

# Extract Exact p value for hubness
UKB_hubness = subset(hubness.vis, hubness.vis$cohort=="UKB")
ABCD_hubness = subset(hubness.vis, hubness.vis$cohort=="ABCD")

UKB.SA = cor.test(UKB_hubness$beta[UKB_hubness$IMG == "SA"], UKB_hubness$hubness[UKB_hubness$IMG == "SA"], method = "pearson")

UKB.CT = cor.test(UKB_hubness$beta[UKB_hubness$IMG == "CT"], UKB_hubness$hubness[UKB_hubness$IMG == "CT"], method = "pearson")

UKB.MC = cor.test(UKB_hubness$beta[UKB_hubness$IMG == "MC"], UKB_hubness$hubness[UKB_hubness$IMG == "MC"], method = "pearson")

UKB.ICVF = cor.test(UKB_hubness$beta[UKB_hubness$IMG == "ICVF"], UKB_hubness$hubness[UKB_hubness$IMG == "ICVF"], method = "pearson")

UKB.ISOVF = cor.test(UKB_hubness$beta[UKB_hubness$IMG == "ISOVF"], UKB_hubness$hubness[UKB_hubness$IMG == "ISOVF"], method = "pearson")

UKB.padj = p.adjust(c(UKB.SA$p.value, UKB.CT$p.value, UKB.MC$p.value, UKB.ICVF$p.value, UKB.ISOVF$p.value), method="fdr")



ABCD.SA = cor.test(ABCD_hubness$beta[ABCD_hubness$IMG == "SA"], ABCD_hubness$hubness[ABCD_hubness$IMG == "SA"], method = "pearson")

ABCD.CT = cor.test(ABCD_hubness$beta[ABCD_hubness$IMG == "CT"], ABCD_hubness$hubness[ABCD_hubness$IMG == "CT"], method = "pearson")

ABCD.MC = cor.test(ABCD_hubness$beta[ABCD_hubness$IMG == "MC"], ABCD_hubness$hubness[ABCD_hubness$IMG == "MC"], method = "pearson")

ABCD.ICVF = cor.test(ABCD_hubness$beta[ABCD_hubness$IMG == "ICVF"], ABCD_hubness$hubness[ABCD_hubness$IMG == "ICVF"], method = "pearson")

ABCD.ISOVF = cor.test(ABCD_hubness$beta[ABCD_hubness$IMG == "ISOVF"], ABCD_hubness$hubness[ABCD_hubness$IMG == "ISOVF"], method = "pearson")

ABCD.padj = p.adjust(c(ABCD.SA$p.value, ABCD.CT$p.value, ABCD.MC$p.value, ABCD.ICVF$p.value, ABCD.ISOVF$p.value), method="fdr")


```

```{r publish figure}

pub.hubness.vis = subset(hubness.vis, hubness.vis$IMG %in% c("CT", "ICVF"))

ggscatter(pub.hubness.vis, x = "beta", y = "hubness", add = "reg.line", conf.int = TRUE, cor.coef = TRUE, cor.method = "pearson", 
          xlab = "PGS beta", ylab = "genetic hubness", size = 1) + geom_point(aes(colour=sig)) + ylim(0,1) + 
  facet_grid(rows = vars(IMG), cols = vars(cohort))

```

